\chapter{Introducción y Estado del Arte}

\section {Introducción}

La astronomía está atravesando una profunda transformación debido al desarrollo de modernos telescopios terrestres y satelitales, que han fomentado la realización de enormes relevamientos astronómicos \cite{Benjamin_2003} \cite{Skrutskie_2006} \cite{gaia} \cite{ogle}. Ante la abrumadora cantidad y calidad de los datos generados, se vuelve necesario el uso de procedimientos automatizados. Consecuentemente, diversas técnicas de aprendizaje automatizado y minería de datos surjen como una elección natural a la hora de analizar y extraer información de modernos datasets astronómicos. \cite{Richards_2011} \cite{303d9825f1794a8b86d692ee85c9a602}\\

\textit{Vista Variables in the Via Lactea (VVV)} es un relevamiento público del infrarrojo cercano que cubrió aproximadamente 520 $deg^2$ del disco y bulbo galáctico, utilizando el telescopio VISTA en Paranal, Chile \cite{vvv} (ver figura \ref{fig:vvv_telescope}). El VVV relevó aproximadamente $10^9$ fuentes astronómicas en las bandas ZYJHK durante un período de 5 años, teniendo entre sus principales objetivos la realización de un mapa tridimensional del bulbo galáctico. \\

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.7\textwidth]{Kap1/telescope.jpg}
\end{center}
\caption[short]{Vista aérea de la plataforma del ``ESO Very Large Telescope (VLT)", en la cima del Cerro Parnal, en el desierto chileno de Atacama. Créditos: J.L. Dauvergne  y G. Hüdepohl }
\label{fig:vvv_telescope}
\end{figure}

\par En este contexto, las estrellas variables de tipo RR Lyrae son una poderosa herramienta para obtener distancias a poblaciones de estrellas en la Vía Láctea, debido a que satisfacen una relación entre sus períodos y sus luminosidades absolutas que permite estimar distancias \cite{Shapley} \cite{Baade}. Sin embargo, a causa de la inmensa cantidad de información generada, la clasificación manual de estrellas se vuelve impracticable. Se requiere, por lo tanto, un método automatizado para identificar estrellas variables de tipo RR Lyrae de entre las $10^6-10^7$ estrellas variables que se espera encontrar en el área explorada \cite{jbc}. \\

\par Investigaciones recientes han mostrado que algoritmos de aprendizaje automatizado basados en ensambles de árboles tienen un excelente desempeño en este tipo de tareas, en tanto que otros métodos tradicionales como Support Vector Machines parecen no ser tan efectivos \cite{elorrieta} \cite{jbc}. El objetivo de esta tesina es intentar mejorar los resultados previos en el problema de detección de RR Lyrae en la VVV utilizando Support Vector Machines, así como comprender por qué métodos basados en ensambles de árboles aparentan funcionar mejor en este tipo de datos.  \\

\par Durante este trabajo se hizo uso de una amplia variedad de técnicas de aprendizaje automatizado, incluyendo diversos tipos de preprocesamiento, reducción de dimensionalidad y selección de variables, visualización de los datos y corrección de imbalance de clases. 

\section {Conceptos astronómicos}

\subsection{Estrellas RR Lyrae}

\par Una \textbf{estrella} es un objeto astronómico que consiste en una esfera luminosa de plasma, la cual mantiene su forma debido a su propia gravedad. Características como luminosidad, tamaño, evolución y duración de vida son definidas principalmente por su masa inicial. \\

\par Aquellas estrellas cuya luminosidad (magnitud aparente\footnote{Este valor indica la medida del brillo y cantidad de energía por segundo por metro cuadrado que se recibe de un objeto celeste por un observador en la Tierra. Como dicha cantidad recibida depende de la transmisión de la atmósfera en dichas bandas, las magnitudes aparentes se normalizan a un valor fuera de la atmósfera terrestre. La escala de magnitudes es una relación inversa logarítmica por la cual la estrella más brillante es la que tiene menor magnitud}) exhibe cambios periódicos o aleatorios se denominan \textbf{estrellas variables.} Las estrellas de tipo variable han jugado un rol crucial en la historia de la astronomía. El Catálogo General de Estrellas Variables \cite{catalogo} enumera más de 110 clases y subclases de estrellas variables. \\

\par Las estrellas variables pueden, en primera instancia, clasificarse en \textbf{variables intrínsecas} y \textbf{variables extrínsecas}, dependiendo del origen de la variabilidad observada. Si la causa de la variabilidad observada es inherente a la estrella, como es el caso de una estrella que periódicamente se expande y contrae, se le denomina intrínseca. Contrariamente, aquellas estrellas cuya variabilidad se debe a factores externos, como un compañero orbital que ocasionalmente la eclipsa, se denominan variables extrínsecas. \\

\par Probablemente el subgrupo más importante de las estrellas variables intrínsecas son las \textbf{estrellas pulsantes}, que varían en radio y luminosidad en el tiempo, expandiéndose y contrayéndose con períodos tan breves como minutos, o tan extensos como años, dependiendo del tamaño de la estrella. Para una revisión moderna de la fenomenología de estrellas pulsantes, puede remitirse a \cite{fisica}. \\

\par  Dentro de las estrellas pulsantes, se encuentran las subclases \textbf{RR Lyrae} y \textbf{Cepheids}, las cuales satisfacen una relación entre sus períodos y sus luminosidades absolutas que las convierte en invaluables herramientas para una de las tareas más complejas en astronomía: estimar distancias \cite{Shapley} \cite{Baade}. \\

\par Las estrellas de tipo \textbf{RR Lyrae} (en adelante, RRL) tienen períodos de entre 0.2 y 1.2 días \cite{smith}, y tienen una edad de aproximadamente 14 Gyr\footnote{1 gigayear (Gyr) = $10^9$ años}. Son consideradas excelentes candelas estándar, especialmente importantes a la hora de explorar distancias y propiedades de viejas problaciones estelares. Basándose en relevamientos recientes, se estima que hay alrededor de 140000 estrellas RRL en nuestra galaxia \cite{ogle} \cite{gaia} \\

\par En base a sus curvas de luz, las RRL fueron originalmente separadas en subtipos a, b y c \cite{bailey}, aunque posteriores trabajos unificaron los dos primeros subtipos en uno solo, RRab, dado que son fundamentalmente distintos del tercero, RRc \cite{schwarzschild}. Adicionales subtipos, extremadamente raros, fueron añadidos posteriormente. \\

\subsection{El relevamiento VVV}

\par ``Vista Variables in the Via Lactea (VVV) ESO Public Survey'' es un relevamiento fotométrico (terrestre) del bulbo galáctico y parte del disco interno de la Vía Láctea, que se llevó a cabo utilizando el telescopio VISTA en Parnal, Chile.  Uno de los objetivos principales de la VVV es adquirir un mayor entendimiento del origen, estructura y evolución de la Vía Láctea. Para una descripción detallada de la VVV puede consultarse \cite{vvv}, en tanto que un artículo más reciente con énfasis en variabilidad puede consultarse en \cite{vvv_actual} \\

\par El VVV, así como su sucesor el ``VVV Survey eXtended'', i.e. VVVX, persiguen el objetivo de producir un atlas profundo de una gran parte del Bulbo de la Vía Láctea, así como de una fracción del Disco Galáctico interno. Este mapa se produjo mediante un monitoreo sistemático de estas regiones, habiéndose completado 1929 horas de observación durante cinco años, comenzando en 2010. \\

\par Dentro del barrido total del relevamiento, es de interés astronómico la generación de catálogos de cualquier tipo de objeto, esperándose identificar no sólo estrellas variables, sino planetas, asteroides y otros fenómenos. En la figura \ref{fig:vvv_objects} se ilustra el número de fenómenos estimado.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\textwidth]{Kap1/vvv_objects.png}
\end{center}
\caption[short]{Número esperado de fenómenos astrofísicos que espera detectar VVV en sus catálogos. Minniti et. al. 2010.}
\label{fig:vvv_objects}
\end{figure}

\par Los datos del VVV se presentan en una unidad llamada baldosa (tile, en inglés), una zona rectangular del cielo de $1.501 deg^2$ relevada a través del tiempo. Se requirieron 196 tiles para mapear el área del Bulbo, así como 152 tiles para el Disco. Cada tile se compone de varias imágenes en alta resolución para diferentes tipos de filtros (bandas anchas) de frecuencias lumínicas en el infrarrojo cercano (cinco en total). Asimismo, por cada imagen existe una base de datos con los valores de posición, magnitud y color de las fuentes de luz presentes en la imagen, llamada “catálogo fotométrico”. En el caso del VVV, la totalidad de las baldosas que constituyeron el relevamiento puede apreciarse en la figura \ref{fig:vvv_tiles} \\

\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{Kap1/vvv_tiles.jpg}
\end{center}
\caption[short]{Área del relevamiento VVV, en coordenadas galácticas. En escala de grises se puede apreciar la densidad estelar del área relevada. ~\protect\cite{Skrutskie_2006}}
\label{fig:vvv_tiles}
\end{figure}

\par La identificación de aquellas fuentes de luz que corresponden a estrellas RRL es de particular interés para VVV, dado que determinar distancias es vital para cumplir uno de sus objetivos primordiales: mapear el Bulbo Galáctico. Más aún, la existencia de trabajos previos \cite{gran1} \cite{gran2} que identifican algunos cientos de fuentes de luz como RRL dentro del área mapeada por la VVV, implica que se cuenta con un conjunto de datos que puede ser utilizado para entrenar y testear clasificadores de aprendizaje automatizado. 

\subsection{Extracción de atributos}

\par En esta tesina se hace un uso extensivo de los datos producidos en \cite{jbc}. Por cada tile en un subconjunto de tiles del relevamiento, se generó un dataset numérico, donde cada fila corresponde a una estrella, descripta por 62 atributos (del inglés, features) numéricas. En esta sección se explicará, a alto nivel, cómo se obtuvieron dichos atributos a partir de las mediciones de fotometría del infrarrojo cercano producidas por VVV. \\

\par Durante el relevamiento VVV se generaron enormes volúmenes de datos (1.4 TB/noche). El pipeline de VVV \cite{emerson} brinda, por cada imagen generada, una base de datos de archivos con los valores de posición, magnitud y color de las fuentes de luz presentes, llamada \textbf{catálogo fotométrico}. Aunque existen varios tipos de catálogos,  sólo dos son utilizados en este trabajo:

\begin{itemize}
\item En primer lugar, el catálogo \textbf{Pawprint Stack} contiene lecturas de los sensores infrarrojos de la cámara VIR-CAM del telescopio VISTA, correspondientes a la observación de un tile en una fecha dada (también llamado época). 
\item En segundo lugar, el catálogo \textbf{Band Merge} se utiliza para tener una lista confiable de estrellas en un cierto tile, dado que ciertas fuentes de luz pueden no estar presentes entre distintos Pawprint Stacks debido a condiciones meteorológicas o problemas en los instrumentos de medición.
\end{itemize}

\par Para determinar la variación en magnitud de cada estrella presente en cada Band Merge, fue necesario identificar todas sus ocurrencias en diferentes Pawprint Stacks. De esta forma, se puede formar una serie temporal de observaciones de la estrella en cuestión, haciendo uso de técnicas de cross-matching \cite{cross}. El resultado son series temporales como la que se puede apreciar en la figura \ref{fig:curva_de_luz}. Nótese que el tiempo de muestreo puede ser muy irregular, por lo que se presupone que es aleatorio. \\


\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{Kap1/light_curve.png}
\end{center}
\caption[short]{Curva de luz de una de las estrellas relevadas por VVV. El eje $x$ muestra el tiempo expresado en días heliocéntricos medios (HJD), en tanto que el eje $y$ muestra la magnitud aparente observada. Cada punto azul corresponde a una observación en un cierto Pawprint Stack, mientras que las líneas rojas indican el error asociado a cada medición. Imagen tomada de la documentación de Carpyncho, \url{https://carpyncho-py.readthedocs.io/} }
\label{fig:curva_de_luz}
\end{figure}

\par Habiéndose obtenido las series temporales de cada estrella, el siguiente paso fue estimar su período. Se utiliza el método de Fast Lomb-Scargle \cite{Lomb:1976wy} \cite{scargle} \cite{VanderPlas_2018} para recuperar cada período, el cual consiste en ajustar una función sinusoidal a los datos muestreados. \\

\par A partir de las curvas de luz y el período estimado, se extrajeron 49 atributos (o características) numéricas utilizando la herramienta \textit{Feets} \cite{cabral2018fats}. Estos atributos se refieren al período, variación de magnitud y morfología de las curvas de luz. Una descripción de cada atributo puede consultarse en el apéndice \ref{AnexoA}. \\

\par Una contribución original de \cite{jbc} fue la inclusión de atributos que describen las temperaturas o colores intrínsecos de cada estrella.  Dado que la presencia de polvo interestelar ocasiona un fenómeno denominado extinción, que provoca un enrojecimiento de los colores, fue necesario realizar una corrección utilizando mapas de extinción \cite{mcwilliam2011rr}. Como resultado final, se extrajeron 13 atributos numéricos describiendo el color de cada estrella. Nuevamente, la lista completa de atributos de color, junto con sus descripciones está disponible en el apéndice \ref{AnexoA}.

\subsection{Descripción de los datos}
\label{tiles_description}
En esta sección se describirán en detalle los datasets generados en \cite{jbc}, que pueden ser accedidos por el público a través de la librería Python \textbf{Carpyncho}\cite{carpynchoToolkit}.\\

Cada dataset generado corresponde a un cierto tile de la VVV. Cada fila de un dado dataset se corresponde a una cierta estrella variable, descripta por 62 atributos numéricos tal y como se describió en la sección anterior. La siguiente tabla resume los datos liberados por Carpyncho:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Tile}  & \textbf{Épocas} & \textbf{Tamaño} & \textbf{RRL} & \textbf{Unknown} & \textbf{RRL / Tamaño} \\ \hline
b206           & 73              & 157825          & 47           & 157778           & 0.03\%                \\ \hline
b214           & 74              & 149557          & 34           & 149523           & 0.02\%                \\ \hline
b216           & 73              & 168996          & 43           & 168953           & 0.03\%                \\ \hline
b220           & 73              & 209798          & 65           & 209733           & 0.03\%                \\ \hline
b228           & 73              & 199853          & 28           & 199825           & 0.01\%                \\ \hline
b234           & 73              & 293013          & 126          & 292887           & 0.04\%                \\ \hline
b247           & 73              & 406386          & 192          & 406194           & 0.05\%                \\ \hline
b248           & 74              & 417839          & 218          & 417621           & 0.05\%                \\ \hline
b261           & 74              & 555693          & 252          & 555441           & 0.05\%                \\ \hline
b262           & 74              & 573873          & 314          & 573559           & 0.06\%                \\ \hline
b263           & 94              & 568110          & 317          & 567793           & 0.06\%                \\ \hline
b264           & 94              & 595234          & 307          & 594927           & 0.05\%                \\ \hline
b277           & 73              & 718567          & 429          & 718138           & 0.06\%                \\ \hline
b278           & 74              & 742153          & 436          & 741717           & 0.06\%                \\ \hline
b360           & 74              & 939110          & 669          & 938441           & 0.07\%                \\ \hline
b396           & 73              & 486639          & 15           & 486624           & 0.00\%                \\ \hline
\textbf{Total} & 1216            & 7182646         & 3492         & 7179154          & 0.05\%                \\ \hline
\end{tabular}
\end{table}

\par Como se puede observar, algunas de las estrellas variables de cada dataset están identificadas como RRL. Estas etiquetas provienen de realizar cross-matching con catálogos de estrellas variables de otros relevamientos con zonas de observación superpuestas a la VVV: \textit{OGLE-III} \cite{Udalski}, \textit{OGLE-IV} \cite{Udalski2} y VizieR \cite{vizier}. \\

\par En todos los experimentos de clasificación de este trabajo, se consideró como clase positiva a aquellas estrellas etiquetadas como RRL, siendo el resto la clase negativa. Es importante mencionar que nuestras clases positivas y negativas no son completamente certeras, dado que no han sido validadas con una inspección manual de cada fuente. Es posible que ciertas estrellas etiquetadas como RRL en realidad no lo sean y viceversa. Esto es especialmente válido en tiles como \textit{b396}, para las cuales hay pocas RRL previamente clasificadas en relevamientos anteriores. \\

\par Para la mayoría de los experimentos en este trabajo, se utilizó un subconjunto de tiles (\textit{b234}, \textit{b261}, \textit{b278} y \textit{b360} ) correspondiente a áreas del Bulbo que resultan de particular interés:

\begin{itemize}
\item Hay una buena densidad de RRL, pues las zonas se superponen bien con relevamientos anteriores. Por lo tanto, es probable que haya menos RRLs etiquetadas como no-RRL.

\item \textit{b278} es de particular interés pues contiene la llamada ventana de Baade, una zona con poco polvo intergaláctico en la línea visual de la tierra al núcleo galáctico \cite{Baade}. Esta zona ha sido históricamente utilizada para estudiar RRL.

\end{itemize}

\section {Aprendizaje automatizado}

Esta sección introducirá brevemente algunos conceptos básicos de aprendizaje automatizado, y está fuertemente basada en los capítulos introductorios de \cite{mitchell} y \cite{statisticallearning}.

\subsection{Definición y tipos de aprendizaje}

El campo del \textbf{aprendizaje automatizado} consiste en el estudio de algoritmos que mejoran automáticamente su rendimiento gracias a la experiencia. Formalmente, Tom Mitchell en su libro \textit{ ``Machine Learning''} \cite{mitchell} define aprendizaje automatizado como sigue:

\begin{quotation}
Se dice que un programa de computadora aprende de la experiencia $E$ respecto a una tarea $T$ y una medida de desempeño $P$, si el desempeño medido con $P$ en una tarea $T$ , mejora con la experiencia $E$.
\end{quotation}

Dada una muestra de datos, los algoritmos de aprendizaje automatizado construyen un modelo con el objeto de realizar predicciones o tomar decisiones \textit{sin haber sido expresamente programados para hacerlo}. Tales algoritmos pueden ser aplicados a un amplio rango de tareas, tales como aprender a conducir un vehículo autónomo \cite{Pomerleau-1989-15721}, aprender a jugar backgammon a nivel profesional \cite{Tesauro1995} o clasificar estructuras astronómicas \cite{clasify_astronomy}.  \\

Tradicionalmente, las distintas tareas a llevar a cabo por algoritmos de aprendizaje automatizado se dividen en tres paradigmas \cite{ai}:

\begin{itemize}
\item \textbf{Aprendizaje supervisado}: Consiste en aprender una función $f : I \mapsto O$, basándose en un conjunto de ejemplos $T \subset I \times O$ . En otras palabras, el algoritmo de aprendizaje automatizado intenta inferir una función a partir de un conjunto de entradas de ejemplo, etiquetadas con su valor de salida. Si el conjunto $O$ es discreto, se trata de una tarea de \textbf{clasificación}; en tanto que si es continuo, se trata de una tarea de \textbf{regresión}.
\item \textbf{Aprendizaje no supervisado}: En aprendizaje no supervisado, sólo hay entradas pero no salidas, por lo que el objetivo es aprender patrones y relaciones en conjuntos de datos no etiquetados.

\item \textbf{Aprendizaje por refuerzo (Reinforcement learning)}: Consiste en aprender a tomar decisiones en un ambiente dinámico, con el objeto de maximizar una cierta noción de recompensa acumulada. 
\end{itemize}

Sin importar el tipo de supervisión, todo aprendizaje automático tiene una fase de entrenamiento y una fase de predicción. La \textbf{fase de entrenamiento} se basa en suministrar datos a los modelos para ajustar sus parámetros internos. Asimismo, hay varios modelos que poseen hiperparámetros que suelen ser configurados previamente a la fase de entrenamiento.  Luego, en la \textbf{fase de predicción}, los modelos pueden usarse para predecir alguna información acerca de datos desconocidos. \\

En este trabajo nos enfocaremos en técnicas de aprendizaje automatizado supervisado, dado que se desea abordar la tarea de clasificar estrellas variables en RRL o no-RRL. 

\subsection{Medidas de performance}
\label{ml_intro_test}

Como se mencionó anteriormente, el aprendizaje supervisado consiste en aproximar una función $f : I \mapsto O$, donde usualmente $I =\mathds{R}^n$ y $O \subseteq \mathds{R}$. Durante una primera fase de entrenamiento, un conjunto de $m$ ejemplos $x_i \in I, \ i=1,\ldots,m$ junto con sus salidas asociadas $y_i \in O$ es utilizado por un cierto algoritmo de aprendizaje automatizado supervisado para producir una estimación de $f$, a la que llamaremos $\hat{f}$. \\

Para evaluar el desempeño de tal algoritmo de aprendizaje automatizado, se necesita alguna forma de medir cuán bien $\hat{f}$ aproxima a $f$. Dado un conjunto de pares etiquetado $ S = \{ (a_i,b_i) \ | \ a_i \in I, \ b_i \in O, \ i=1,\ldots,k \}$, las siguientes métricas son de interés:

\begin{itemize}

\item  En problemas de regresión, la métrica más comúnmente utilizada es el \textit{error cuadrático medio}:

\begin{center}
$MSE = \sum\limits_{i=1}^{k} ( b_i - \hat{f}(a_i) )^2 $
\end{center}

\item En problemas de clasificación, podemos calcular la proporción de errores realizados:

\begin{center}
$Error \ Rate = \frac{1}{k} \sum\limits_{i=1}^{k} I( b_i , \hat{f}(a_i) ) $
\end{center}

Donde:
\begin{center}
$
I(y_i,\hat{y_i}) =
\left\{
	\begin{array}{ll}
		0  & \mbox{si } y_i = \hat{y_i} \\
		1 & \mbox{si } y_i \neq \hat{y_i}
	\end{array}
\right.
$
\end{center}

\end{itemize}

Si $S$ es exactamente el conjunto de entrenamiento, entonces ambas métricas se llaman \textit{training MSE} y \textit{training Error Rate} respectivamente; y nos indican cuán bien $\hat{f}$ aproxima a $f$ para los elementos de entrenamiento. Sin embargo, en general, estamos interesados en evaluar el desempeño del clasificador en elementos nuevos que no pertenecen al conjunto de entrenamiento.  \\

Usualmente, se reserva una porción de los datos disponibles para ser utilizada como \textbf{conjunto de test}. Estos datos no son utilizados en la fase de entrenamiento, sino que son utilizados para calcular métricas como \textit{test Error Rate} una vez terminada la fase de entrenamiento. Métricas calculadas sobre un conjunto de test proveen una noción de cuán bien el clasificador funcionará en datos no antes vistos. \\

Una alternativa para medir cuán bien $\hat{f}$ aproxima a $f$ sin necesidad de tener que separar los datos etiquetados disponibles en un conjunto de entrenamiento y uno de testeo es utilizar \textbf{cross validation} \cite{cross_validation}. Dado un dataset de elementos del dominio etiquetados $D$, cross validation consiste en:
\label{cross_validation}
\begin{enumerate}
\item Permutar los elementos de $D$ de forma aleatoria.
\item Particionar $D$ en $k$ grupos
\item Para cada partición $p$:
\begin{itemize}
\item Entrenar el algoritmo de aprendizaje automatizado utilizando todas las particiones excepto $p$
\item Utilizar el modelo entrenado para realizar predicciones sobre los elementos de $p$, calculando la métrica de performance deseada (por ejemplo, $Error \ rate$).
\item Guardar la métrica obtenida, y descartar el modelo entrenado.
\end{itemize}
\item Combinar las $k$ métricas obtenidas, por ejemplo calculando su promedio. El valor obtenido representa la performance del algoritmo de aprendizaje automatizado sobre la totalidad de los datos.
\end{enumerate}

\subsection{Medidas de performance en clasificación binaria}

En este trabajo estamos particularmente interesados en problemas de \textbf{clasificación binaria}, es decir, problemas de aprendizaje automatizado supervisado en los cuales el conjunto de etiquetas contiene solo dos elementos, o clases, a menudo llamados clase positiva y negativa. En el contexto de clasificación binaria, dado un modelo entrenado, cada elemento se puede clasificar en una de las siguientes cuatro categorías: \\

\begin{table}[h!]
\begin{tabular}{l|l|l|}
\cline{2-3}
                                                    & \textbf{Clase predicha: Negativa} & \textbf{Clase predicha: Positiva} \\ \hline
\multicolumn{1}{|l|}{\textbf{Clase real: Negativa}} & Verdadero negativo (TN)           & Falso positivo (FP)               \\ \hline
\multicolumn{1}{|l|}{\textbf{Clase real: Positiva}} & Falso negativo (FN)               & Verdadero positivo (TP)           \\ \hline
\end{tabular}
\end{table}

Los falsos positivos son aquellos elementos de clase negativa, clasificados incorrectamente por el modelo con etiqueta positiva. Similarmente, los falsos negativos son aquellos elementos con etiqueta positiva, clasificados como negativos. Los verdaderos positivos (negativos), son aquellos elementos positivos (negativos), que fueron clasificados correctamente. \\

Dado un conjunto de testeo, la performance de un clasificador binario puede visualizarse al calcular una \textbf{matriz de confusión}. La matriz de confusión mostrará la suma de elementos de cada una de las cuatro categorías explicadas. En particular, podemos reescribir la métrica Error Rate como: \\

\begin{center}
$ Error Rate = \frac{FP + FN}{FP + FN + TP + TN} $
\end{center}

Equivalentemente, es usual analizar la \textbf{tasa de aciertos}:

\begin{center}
$ Acc = \frac{TP + TN}{FP + FN + TP + TN} $
\end{center}

Otras métricas de interés son:

\begin{itemize}
\item \textbf{Precisión}: La proporción de instancias clasificadas como positivas, que realmente lo son:
\begin{center}
$ Precision =  \frac{TP}{TP + FP}$
\end{center}

\item \textbf{Recall}: La proporción de instancias positivas que son detectadas por el clasificador.
\begin{center}
$ Recall =  \frac{TP}{TP + FN}$
\end{center}

\end{itemize}

\subsection{El dilema sesgo-varianza}

En esta sección, se discutirá brevemente el dilema sesgo-varianza en aprendizaje automatizado \cite{statisticallearning}. Supongamos que la variable que estamos intentando predecir es $Y$, basándonos en un conjunto de atributos $X$. Asumimos que hay una relación subyacente entre ambos:

\begin{center}
$Y = f(X) + \epsilon$
\end{center}

Donde $\epsilon$ se distribuye de forma normal, con media cero y varianza $\sigma^2$, y representa ruido en los datos. Utilizando algún algoritmo de aprendizaje automatizado, y a partir de un dataset de entrenamiento $D$, se obtiene un modelo $\bar{f}$ que intenta aproximar $f$. El error cuadrático de predicción para un input $x$ es\footnote{Nótese que las esperanzas se calculan sobre las diferentes elecciones de dataset de entrenamiento $D$.}:

\begin{center}
$Err(x) = E[(Y-\bar{f}(x))^2]$
\end{center}

Lo cual puede reescribirse como:

\begin{center}
$Err(x) = (E[\bar{f}(x)]-f(x))^2 + E[(\bar{f}(x)-E[\bar{f}(x)])^2] + \sigma^2$ 
\end{center}

Donde podemos darle un nombre a cada término de esa suma:

\begin{center}
$Err(x) =  Sesgo^2 + Varianza + Error Irreducible$
\end{center}



El \textbf{error irreducible}, que es la varianza de la función objetivo, está fuera de nuestro control. No puede ser reducido creando buenos modelos, y es una medida de la cantidad de ruido en nuestros datos. Los otros dos términos, en cambio, están bajo nuestro control.\\

El \textbf{sesgo} es la diferencia entre la predicción promedio de nuestro modelo, y el valor correcto que intentamos predecir. Este error puede ser pensado como el error causado por asunciones simplistas del modelo, como por ejemplo asumir que la distribución de los datos es lineal. Un modelo con alto sesgo presta muy poca atención a los datos de entrenamiento. \\

La \textbf{varianza} es la variabilidad de la predicción de un modelo, es decir, cuánto varía $\bar{f}(x)$ alrededor de su media. Modelos con alta varianza prestan mucha atención a los datos de entrenamiento, pero no generalizan tan bien en datos no vistos anteriormente. \\

De forma general, cuando la complejidad de nuestro modelo crece, la varianza tiende a aumentar en tanto que el sesgo disminuye. Lo opuesto sucede cuando la complejidad del modelo disminuye. \\

La figura \ref{fig:tradeoff} muestra el comportamiento típico de la varianza y el sesgo en función de la complejidad del modelo. El error de entrenamiento tiende a decrecer cuando incrementamos la complejidad del modelo, es decir, cuando ajustamos los datos con mayor precisión. Sin embargo, un exceso de ajuste (\textbf{overfitting}) conduce a un modelo que se adapta demasiado a los datos de entrenamientos, y no generaliza bien en test. En este caso, las predicciones tendrán gran varianza. En contraste, si el modelo no es muy complejo, no se ajusta lo suficiente a los datos de entrenamiento (\textbf{underfitting}) y tendrá un alto sesgo, resultando nuevamente en alto error de generalización.\\ 

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.7\textwidth]{Kap1/tradeoff.png} 
  \end{center}
 \caption{ Error de test y de entrenamiento en función de la complejidad del modelo. Créditos: \protect\cite{statisticallearning} }
\label{fig:tradeoff}
\end{figure}

Como se puede ver en la figura \ref{fig:tradeoff}, el error de entrenamiento será muy bajo en modelos complejos. Sin embargo, sería inadecuado utilizar el error de entrenamiento como una medida de cuán bien el modelo funciona, pues puede no funcionar tan bien en un conjunto de testeo no antes visto. Por este motivo es que se deben utilizar métricas calculadas sobre los datos de testeo para realizar afirmaciones sobre la performance de un modelo. \\

Utilizar métricas obtenidas a través de cross-validation también es correcto, pues debe notarse que en el procedimiento descripto en la sección \ref{cross_validation} las métricas de cada partición siempre se calculan sobre datos que no han sido utilizados para entrenar los modelos.

\subsection{Problemas desbalanceados}
\label{imbalance}

A la hora de estudiar problemas de clasificación, es importante tener en cuenta la proporción de datos de cada clase. Un \textbf{problema de clasificación desbalanceado} es aquel en el cual la cantidad de elementos de cada clase no es proporcional. Ciertas aplicaciones como diagnóstico médico o detección de transacciones fraudulentas con tarjeta de crédito presentan datasets con un número muy pequeño de instancias positivas\footnote{En problemas de clasificación binaria, usualmente se considera clase positiva a la clase minoritaria, en tanto que la clase mayoritaria es la negativa}, que son sin embargo cruciales de clasificar correctamente \cite{imbalanced_svm}. \\

Si se utilizan datasets imbalanceados para entrenar y testear, es inadecuado utilizar métricas de desempeño basadas en clasificar la \textit{mayor cantidad} de elementos de forma correcta, como $Acc$. La hipótesis mas sencilla, clasificar todas las instancias como pertenecientes a la clase mayoritaria, a menudo maximiza tales métricas. \\

Un primer paso a la hora de trabajar con datos desbalanceados es, entonces, utilizar métricas que no son sensitivas al imbalance de clases. En clasificación binaria precision y recall son métricas adecuadas. \\

A menudo, muchos métodos de aprendizaje automatizado para clasificación binaria producen un puntaje\footnote{Se utiliza el término puntaje (del inglés \textit{score}), dado que no se utilizará un enfoque probabilístico.} en $[0,1]$ para cada instancia a clasificar. Puntajes cercanos a 0 indican que el clasificador tiene mayor certeza de que una cierta entrada pertenece a la clase negativa, en tanto que valores cercanos a 1 indican pertenencia a la clase positiva. \\

En tal escenario, resulta necesaria la elección de un umbral $t \in [0,1]$, de forma tal que sólo instancias cuyos puntajes son mayores a $t$ sean clasificadas como positivas, siendo las demás negativas. En consecuencia, resulta importante determinar un $t$ adecuado para el dominio de aplicación en estudio, dado que distintos valores de $t$ tendrán un impacto directo en la matriz de confusión producida. \\

Valores altos de $t$ tenderán a producir clasificadores con mayor precisión y menor recall, en tanto que valores pequeños de $t$ tenderán a clasificadores con mayor recall y menor precisión. Una forma gráfica de analizar esta correspondencia es a través de la curva de precision-recall del clasificador, como la de la figura \ref{fig:prc}, en la cuál se grafica la precisión y el recall obtenidos para un rango de valores de $t$. \\

\begin{figure}[h]
\begin{center}
\includegraphics[width=.6\textwidth]{Kap1/PRc.png}
\end{center}
\caption[short]{Ejemplo de una curva de precision-recall. Cada punto de la curva corresponde a la precisión y el recall obtenidos para un cierto valor de $t$. }
\label{fig:prc}
\end{figure}

Si se está abordando un problema desbalanceado, una forma determinar si un clasificador tiene mejor performance que otro es comparar sus curvas de precision-recall en el dataset de test. Dado que las curvas de precision-recall tienden a ser bastante ruidosas en áreas de bajo recall, en este trabajo se utilizó en repetidas ocasiones el área bajo la curva de precision-recall restringida al dominio [0.35,1] para obtener una medida de performance numérica, a la que llamaremos R-AUPRC (del inglés Robust Area Under the Precision Recall Curve, área debajo de la curva de precision-recall robusta).\\


R-AUPRC resulta útil cuando se desea comparar decenas o cientos de curvas a la vez, siendo imposible su inspección visual y prefiriéndose aquel modelo que maximiza el R-AUPRC. Otra métrica alternativa es utilizar la precisión del clasificador a un cierto valor fijo de recall. \\

Además de utilizar métricas adecuadas para evaluar el desempeño, otras técnicas para trabajar con datos desbalanceados son:

\begin{itemize}
\item Corregir manualmente el imbalance de clases en los datos. Una posibilidad es eliminar datos de la clase mayoritaria aleatoriamente (\textbf{undersampling}) \cite{nathalie} hasta alcanzar el balance deseado. Una segunda posibilidad es generar nuevas instancias de la clase minoritaria (\textbf{oversampling}). \cite{he}
\item Forzar a que el clasificador preste más atención a la clase minoritaria \cite{imbalanced_svm}. Por ejemplo, como se verá en secciones posteriores, para ciertos métodos de aprendizaje automatizado como Support Vector Machines es posible asociar un peso (\textit{class\_weight}) a cada clase, de tal forma que el clasificador será menos permisivo a la hora de clasificar incorrectamente clases con alto peso.
\end{itemize}

\subsection{Árboles de decisión}
Esta sección está enteramente basada en \cite{statisticallearning}, y presentará uno de los métodos de aprendizaje automatizado supervisado para clasificación más ampliamente utilizados: Árboles de Decisión. \\

Los métodos basados en árboles particionan el dominio de los atributos en un conjunto de rectángulos, y luego ajustan un modelo sencillo a cada uno. Son conceptualmente simples, pero poderosos.\\

Consideremos un problema de regresión donde se intenta predecir una variable continua Y, basándose en dos atributos $X_1$ y $X_2$, ambos tomando valores en el intervalo $[0,1]$. \\

La figura \ref{fig:arboles_hastie_1}(a) muestra una partición del espacio de atributos. Se utilizó una partición simple, restringiéndose a particiones recursivas binarias. En primer lugar se dividió el espacio en dos regiones, y se modeló la respuesta de la media de Y en cada región. Se escogió el atributo y el punto de división (split) para encontrar el mejor ajuste. Recursivamente, cada una de las dos regiones obtenidas se divide en otras dos regiones, hasta alcanzar algún criterio de terminación. \\

\begin{figure}[h!]
\begin{tabular}{ccc}
  \includegraphics[width=0.32\textwidth]{Kap1/cart1.png} &     \includegraphics[width=0.32\textwidth]{Kap1/cart2.png} &
    \includegraphics[width=0.32\textwidth]{Kap1/cart3.png}
    \\
(a)  & (b) & (c) 
\end{tabular}
\caption{Ejemplo de un árbol de decisión sencillo. Fuente: \protect\cite{statisticallearning} }
\label{fig:arboles_hastie_1}
\end{figure}

En el ejemplo de la figura  \ref{fig:arboles_hastie_1}(a), primero se dividió el espacio de atributos en $X_1 = t_1$. Luego, la región $X_1 \leq t_1$ se dividió en $X_2 = t_2$ y la región $X_1 > t_1$ se dividió en $X_1 = t_3$. Finalmente, la región $X_1 > t_3$ se dividió en $X_2 = t_4$. El resultado de este proceso es una partición en cinco regiones $R_1, R_2, \ldots, R_5$. El modelo de regresión producirá predicciones constantes $c_1, \ldots, c_5$ de $Y$ para una nueva instancia de acuerdo a la partición en que sus atributos se encuentren:

\begin{center}
$\hat{f}(X) = \sum\limits_{m=1}^5 ( c_m I\{(X_1,X_2) \in R_m\} )$
\end{center}

Este mismo modelo puede ser representado por el árbol de decisión binario de la figura \ref{fig:arboles_hastie_1}(b). El dataset completo se encuentra en la raíz, en la parte superior del árbol. Instancias que satisfacen la condición en cada nodo son asignadas a la rama izquierda, en tanto que las otras son asignadas a la rama derecha. Los nodos terminales del árbol (también llamados hojas) corresponden a las regiones $R_1, \ldots, R_5$. La superficie de decisión obtenida para $c_1=-5, c_2=-7, c_3=0, c_4=2, c_5=4$ puede ser observada en la figura \ref{fig:arboles_hastie_1}(c). \\

Una de las ventajas clave de los árboles de decisión binarios es su interpretabilidad, incluso cuando hay más de dos atributos.

\subsubsection{Cassification And Regression Tree (CART)}
\label{cart}
Veamos a continuación cómo se construye un árbol de decisión utilizando el algoritmo CART. Supongamos que el problema consta de $p$ atributos de entrada y una variable de salida, y se cuenta con $N$ observaciones $(x_i,y_i)$ para $i=1,\ldots,n$, donde $x_i=(x_{i1},\ldots, x_{ip})$. El algoritmo necesita automáticamente decidir qué variables y qué valores de tales variables utilizará en cada nodo (split), así como la topología (forma) del árbol. \\

Supongamos que tenemos una partición del dominio en M regiones $R_1, \ldots, R_M$, y modelamos la respuesta con una constante $c_m$ en cada región:

\begin{center}
$f(X) = \sum\limits_{m=1}^M c_m I\{(X_1,X_2) \in R_m\}$
\end{center}

Si el problema es de regresión, adoptando como criterio de minimización la suma de los errores cuadráticos $\sum\limits(y_i - f(x_i))^2$, es sencillo ver que el mejor $\hat{c}_m$ es el promedio de $y_i$ en la región $R_m$:

\begin{center}
$\hat{c}_m = avg(y_i \ | \ x_i \in R_m)$
\end{center}

En problemas de clasificación, puede usarse la etiqueta más frecuente (moda) de $y_i$ en la región $R_m$. \\

Para encontrar la mejor partición binaria se utiliza un algoritmo greedy, buscando la variable $j$ y el valor de división $s$ que resuelve:

\begin{center}
$ \min\limits_{j,s}[ \min\limits_{c_1} \sum\limits_{x_i \in R_1(j,s)} (y_i - c_1)^2 + 	\min\limits_{c_2} \sum\limits_{x_i \in R_2(j,s)} (y_i - c_2)^2  ]$
\end{center}

Donde $R_1(j,s) = \{ X | X_j \leq s \}$ y $R_2(j,s) = \{ X | X_j > s \}$. \\

En problemas de clasificación, se utilizan otras métricas para decidir cuál es el mejor valor de corte (split), intentando incentivar la homogeneidad de la variable objetivo en los subconjuntos producidos. Dos métricas muy populares son \textit{Gini Impurity} e \textit{Information Gain} \cite{ginigain}.\\

Para cada variable, determinar el mejor punto de división $s$ puede hacerse muy rápidamente y por lo tanto, escaneando todos los atributos, se puede hallar el mejor par $(j,s)$. \\

Habiendo encontrado la mejor división, se particionan los datos en las dos regiones resultantes y se repite recursivamente el proceso de división en cada una de las dos regiones. Una cuestión a considerar es cuándo detener este proceso, pues árboles muy grandes pueden sobreajustar los datos, en tanto que árboles muy pequeños pueden no capturar la estructura del problema. La estrategia preferida es construir un árbol grande, deteniendo el proceso de división cuando una cantidad mínima de de nodos es alcanzada. Posteriormente, este árbol es \textit{podado}, reduciendo su tamaño. 


\subsubsection{Otras consideraciones sobre árboles de decisión}

\begin{itemize}
\item El algoritmo previamente descripto, CART, es uno de los métodos más populares para construir árboles de decisión. Otras opciones ampliamente utilizadas incluyen ID3 \cite{id3}, C4.5 \cite{c45} y C5.0 \cite{noauthororeditor2013applied}.
\item Los árboles de decisión son un ejemplo de un modelo que tiene bajo sesgo, pues no hacen casi ninguna asunción acerca de la función objetivo. Sin embargo, los árboles de decisión complicados (profundos) son modelos con alta varianza, pues son altamente susceptibles a variaciones en los datos de entrenamiento y tienden a sobreajustar. Técnicas de podado (prunning) pueden ser utilizadas para reducir la complejidad de los árboles y evitar sobreajustar los datos de entrenamiento.
\end{itemize}


\subsection{Random Forests}

En esta sección se introducirá uno de los dos métodos de clasificación utilizados en este trabajo: Random Forests \cite{rf}, y está basada enteramente en \cite{statisticallearning}.

\subsubsection{Métodos bootstrap}

Bootstrap es una técnica general para analizar estadísticas sobre una población. Supongamos que tenemos un modelo de aprendizaje automatizado, entrenado con un cierto conjunto de datos $Z=(z_1, \ldots, z_N)$ donde $z_i=(x_i,y_i)$. La idea básica es muestrear datasets aleatoriamente con reemplazo a partir de $Z$, cada uno con el mismo tamaño que $Z$. \\

Este procedimiento se repite $B$ veces, produciendo $B$ datasets bootstrap. Cada dataset bootstrap construido se utilizará como conjunto de entrenamiento para entrenar un nuevo modelo de aprendizaje automatizado. Finalmente, se examina el comportamiento de los distintos modelos entrenados sobre las B réplicas, tal y como se muestra en la figura \ref{fig:bootstrap}. \\


\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.56\textwidth]{Kap1/bootstrap.png} 
\end{center}
\caption{ Semántica del proceso bootstrap. Se desea estimar la precisión estadística de una métrica $S(Z)$ computada sobre un dataset $Z$. $B$ datasets de entrenamiento $Z^{*b}$, cada uno con tamaño $N$, son muestreados con reemplazo a partir del dataset original $Z$. La métrica de interés $S(Z)$ se computa sobre cada dataset bootstrap, y los valores $S(Z^{*1}), \ldots, S(Z^{*N})$ pueden usarse para estimar la precisión estadística de $S(Z)$.  Fuente: \protect\cite{statisticallearning} }
\label{fig:bootstrap}
\end{figure}


En la figura, $S(Z)$ es algún tipo de métrica computada a partir de los datos $Z$. Una posibilidad sería que $S(Z)$ fuese el error de predicción sobre Z. Sin embargo, esto sería metodológicamente incorrecto pues muchos de los elementos del conjunto de entrenamiento estarían actuando como elementos del conjunto de testeo. Esta superposición puede hacer que los resultados sean incorrectamente optimistas.  \\

Emulando la idea aplicada en Cross Validation (\ref{cross_validation}), una mejor estimación sería únicamente considerar predicciones obtenidas con bootstraps que no contienen esa observación.  Las métricas obtenida nos permiten estimar el error en test de un cierto clasificador.

\subsubsection{Bagging}

Se presentó boostrap como una forma de estimar el error en test de un modelo. En esta subsección, se mostrará cómo utilizar bootstrap para mejorar las predicciones en sí mismas. \\

Consideremos en primera instancia un problema de regresion. Supongamos que se cuenta con un conjunto de entrenamiento $Z=(z_1, \ldots, z_N)$ donde $z_i=(x_i,y_i)$, y se calculan  $B$ boostrap datasets a partir de él. \\

Bootstrap aggregation o \textbf{bagging} \cite{breiman96} consiste en entrenar un modelo con cada bootstrap dataset $Z^{*b}$, cada uno de los cuales produce una predicción $\hat{f}^{*b}(x)$ para un dado input $x$. Posteriormente, se utiliza el promedio de todas las predicciones como predicción final, por lo tanto reduciendo la varianza del resultado:

\begin{center}
$\hat{f}_{bag} = \frac{1}{B} \sum\limits_{b=1}^B \hat{f}^{*b}(x)$
\end{center}

Por otro lado, en un problema de clasificación, puede utilizarse la moda de las predicciones asociadas a cada bootstrap como predicción final. \\

Bagging tiene la capacidad de reducir dramáticamente la varianza de predictores inestables como árboles sin introducir sesgo, lo cual conduce a mejores resultados. Cada árbol entrenado con un bootstrap dataset diferente tenderá a involucrar diferentes atributos, y a tener una topología diferente, tal y como se puede ver en la figura \ref{fig:bootstrap_trees}. 

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.56\textwidth]{Kap1/bootstrap_trees.png} 
\end{center}
\caption{ En esta imagen puede verse un árbol de decisión, en color naranja, construido a partir de un cierto dataset. Los restantes 11 árboles fueron construidos a partir de distintos bootstraps del dataset en cuestión. Nótese que la topología de los árboles y las variables utilizadas en cada nodo son notablemente distintas para cada $b$. Fuente: \protect\cite{statisticallearning} }
\label{fig:bootstrap_trees}
\end{figure}


\subsubsection{Random Forest}

La idea esencial de bagging es promediar muchos modelos ruidosos que tienen bajo sesgo, reduciendo la varianza. Los árboles de decisión son candidatos ideales para bagging, dado que pueden capturar interacciones de estructuras complejas en los datos, y tienen un sesgo relativamente bajo si se les permite tener profundidad suficiente. 

\begin{itemize}
\item Dado que cada árbol generado en bagging está idénticamente distribuido, la esperanza del promedio de $B$ árboles es igual a la esperanza de cualquiera de ellos. Esto implica que el sesgo de bagging con árboles de decisión es el mismo que el de árboles de decisión individuales.
\item Dadas $B$ variables aleatorias idénticamente distribuidas, no necesariamente independientes y con correlación a pares positiva $\rho$, la varianza del promedio es:

\begin{center}
$\rho \sigma^2 + \frac{1-\rho}{B} \sigma^2$
\end{center}

Para $B$ suficientemente grande, el segundo término desaparece, y sigue que el tamaño de la correlación a pares de los árboles calculados sobre cada bootstrap limita los beneficios del promedio.
\end{itemize}

\textbf{Random forest} \cite{rf}, en adelante RF, es una modificación sustancial de bagging que intenta mejorar la reducción de varianza obtenida por bagging reduciendo la correlación entre los árboles. Un RF formado por $B$ árboles de decisión, se construye de la siguiente forma:

\begin{enumerate}
\item Para b=1 hasta B:
\begin{enumerate}
\item Muestrear un bootstrap $Z^{*b}$ de tamaño $|Z|$ a partir de los datos de entrenamiento $Z$.
\item Entrenar un árbol de decisión $T_b$ utilizando $Z^{*b}$ como dataset de entrenamiento, repitiendo los siguientes pasos para cada nodo terminal del árbol, hasta que una cantidad mínima de nodos $n_{min}$ se haya alcanzado:
\begin{enumerate}
\item Seleccionar $m$ atributos aleatoriamente de entre los $p$ atributos.
\item Elegir el mejor atributo y el mejor punto de corte (split) de entre los $m$ atributos seleccionados.
\item Dividir el nodo en dos nodos hijos.
\end{enumerate}
\end{enumerate}
\item Retornar el ensamble de arboles $\{ T_b \}^B_1$
\end{enumerate}

Para realizar una predicción de un nuevo punto, utilizamos el promedio de la predicción de todos los árboles (regresión) o la moda de las predicciones (clasificación). \\

La reducción de correlación entre los árboles sucede en la fase de entrenamiento, al seleccionar $m \leq p$ de los atributos aleatoriamente como candidatos para cada nodo. Intuitivamente, valores pequeños de $m$ reducirán la correlación entre cada par de árboles del ensamble, y por lo tanto, reducirán la varianza en promedio. \\

Una característica importante de RF es el potencial uso de elementos OOB (out-of-bag). Para cada observación $z_i \in Z$, es posible construir una predicción RF promediando sólo las predicciones de aquellos árboles correspondientes a bootstraps $Z^{*b}$ en los cuales $z_i$ no fue muestreado. Esto implica que podemos calcular una estimación de cuán bien el predictor funcionará en instancias no antes vistas, con un razonamiento similar al utilizado en Cross Validation. \\

RF es un método muy flexible y poderoso, y es cotidianamente utilizado en aplicaciones industriales. Una de sus principales ventajas es su facilidad de uso, dado que no se requiere una optimización de hiperparámetros muy compleja y brinda generalmente buenos resultados en datasets arbitrarios.

\subsection{Support Vector Machines}

\label{trick}

En esta sección se presentará el segundo método de aprendizaje automatizado supervisado para clasificación binaria que se utilizará en este trabajo: Support Vector Machines (SVM) \cite{svm2} \cite{svm}  \\

Una tarea de clasificación binaria puede ser vista como la tarea de separar las clases en el espacio de atributos. En la figura \ref{fig:sv1} podemos ver un ejemplo en el cual se decide utilizar un hiperplano para realizar dicha separación. Como se puede ver hay infinitos separadores lineales para este ejemplo. \\


\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.56\textwidth]{Kap1/svm1.png} 
\end{center}
\caption{ En esta imagen podemos ver un ejemplo de clasificación binaria utilizando un separador lineal. Se ilustra la existencia de múltiples separadores lineales que podrían ser utilizados. Créditos: Drew Wilimitis, \url{towardsdatascience.com}.}
\label{fig:sv1}
\end{figure}

Dado un conjunto de entrenamiento $\{ (x_i,y_i), \ i=1,\ldots,N, \ x_i \in \mathds{R}^p , y_i \in \{1,-1\} \}$, un hiperplano se define como:

\begin{center}
$\{ x : f(x) =  x^T\beta + \beta_0 = 0 \}$
\end{center}

Donde $\beta$ es un vector unitario. Una regla de clasificación inducida por $f(x)$ es:

\begin{center}
$G(x) = sign[x^T\beta + \beta_0]$
\end{center}

La función $f(x_0)$ es la distancia de un punto $x_0$ al hiperplano $x^T\beta + \beta_0 = 0$. Si las clases son separables, es posible encontrar $\beta$ y $\beta_0$ tal que $y_i f(x_i) > 0$ $\forall i$. Las SVM buscan elegir el hiperplano que separe ambas clases maximizando el margen entre ambas clases, donde el margen se define como la mínima distancia entre un punto de training y el hiperplano separador. Esta situación se ilustra en la figura \ref{fig:svm_3}. \\

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.56\textwidth]{Kap1/svm3.png} 
  \end{center}
 \caption{En esta imagen se ilustra el hiperplano escogido por SVM. Aquellos puntos que están a la menor distancia del hiperplano separador se denominan vectores soporte. SVM escoge el hiperplano que maximiza la separación entre ambas clases. Créditos: Drew Wilimitis, \url{towardsdatascience.com}}
\label{fig:svm_3}
\end{figure}

El siguiente problema de optimización captura este concepto \cite{statisticallearning}:

\begin{center}
$\min\limits_{\beta, \beta_0}   \| \beta \|$\\
$\textrm{sujeto a} \quad  y_{i}(x_i^T \beta + \beta_0)
  \geq 1, \ i=1,\ldots,N$    \\
\end{center}

Un primer problema a considerar es que las clases pueden estar superpuestas en el espacio de atributos. Una forma de lidiar con esta superposición consiste en maximizar el margen, pero permitir que algunos puntos estén en el lado equivocado, como se ilustra en la figura \ref{fig:svm_5}. Con este propósito, se definen variables slack $\xi=(\xi_1, \ldots, \xi_N)$, y se modifica el problema de optimización como sigue:

\begin{center}
$\begin{aligned}
\min\limits_{\beta, \beta_0}  & \| \beta \| \\
\textrm{sujeto a} \quad  y_{i}(x_i^T \beta + \beta_0) 
  \geq& 1 - \xi_i, \ \  i=1,\ldots,N    \\
  \xi_i \geq& 0  \ \  i=1,\ldots,N    \\
  \sum\limits_{i=0}^N \xi_i \leq& \ constant.
\end{aligned}
$
\end{center}


\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.4\textwidth]{Kap1/slack.jpg} 
  \end{center}
 \caption{ Utilización de variables slack que permiten a algunos puntos de entrenamiento estar dentro del margen, e incluso del lado equivocado del hiperplano. El parámetro C permite regular cuán permisivo es el modelo a la hora de permitir errores de clasificación. Imagen tomada de \textit{Hybrid Model Based on Genetic Algorithms and SVM Applied to Variable Selection within Fruit Juice Classification}, Carlos Fernandez-Lozano et al. }
\label{fig:svm_5}
\end{figure}

Computacionalmente es conveniente re-expresar este problema como sigue:

\begin{center}
$\begin{aligned}
\min\limits_{\beta, \beta_0} \   \frac{1}{2} \| \beta \|^2 &+ C \sum\limits_{i=1}^N \xi_i \\
\textrm{sujeto a} \quad  y_{i}(x_i^T \beta + \beta_0)
  &\geq 1 - \xi_i, \ \ i=1,\ldots,N    \\
  \xi_i &\geq 0 \ \ i=1,\ldots,N    \\
\end{aligned}
$
\end{center}

Donde el parámetro de costo (o regularización) $C$ reemplaza la restricción $\sum\limits_i \xi_i \leq constant$. Los detalles matemáticos de la resolución de este problema de optimización utilizando multiplicadores de Lagrange pueden ser consultados en \cite{statisticallearning}. \\

\subsubsection{El truco del kernel}

El algoritmo descripto tiene una importante limitación: sólo es capaz de encontrar fronteras lineales en el espacio de atributos. Esto puede solucionarse mediante el uso de una función $\phi$ que mapea los datos a algún espacio de mayor dimensionalidad donde, potencialmente, las clases serán separables por una frontera lineal. Esta situación es ilustrada en la figura \ref{fig:svm_4}\\

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.7\textwidth]{Kap1/svm5.png} 
  \end{center}
 \caption{ Utilización de una función kernel para mapear puntos que no son linealmente separables a un espacio de mayor dimensionalidad, donde pueden ser separados por un hiperplano. Créditos: Drew Wilimitis, \url{towardsdatascience.com} }
\label{fig:svm_4}
\end{figure}


\begin{center}
$\begin{aligned}
\min\limits_{\beta, \beta_0}   \frac{1}{2} \| \beta \|^2 &+ C \sum\limits_{i=1}^N \xi_i \\
\textrm{sujeto a} \quad  y_{i}(\phi(x_i)^T \beta + \beta_0)
  &\geq 1 - \xi_i, i=1,\ldots,N    \\
  \xi_i &\geq 0 \ \forall i 
\end{aligned}
$
\end{center}

La solución a este nuevo problema de optimización toma la forma:

\begin{center}
$\hat{f}(x) = \sum\limits_{i=1}^N \hat{\alpha_i} y_i K(x,x_i) + \hat{\beta}_0$ 
\end{center}

Donde $K(a,b) = \langle \phi(a),\phi(b) \rangle$. Nuevamente, el lector puede consultar los detalles matemáticos en \cite{statisticallearning}. Un punto clave es que la solución sólo involucra productos internos en el espacio de mayor dimensionalidad, por lo que nunca es necesario calcular el mapeo explícito de alguna instancia $x$ a $\phi(x)$. Todo lo que se requiere es definir una \textbf{función kernel} $K$ que calcule el producto interno en el espacio de mayor dimensionalidad. Las tres elecciones más populares de kernel son:

\begin{itemize}
\item \textbf{Lineal}: $K(x_i,x_j) = x_i^T x_j$
\item \textbf{Polinomial}: $K(x_i,x_j)= (\gamma x_i^T x_j + r)^d , \ \gamma > 0$
\item \textbf{Radial Basis Function} (RBF)\footnote{El kernel RBF, también llamado Gaussiano, puede reescribirse como $K(x_i,x_j)=\sum\limits_{n=0}^{+\infty}\frac{(x_i.x_j)^n}{\sigma^n.n!}$. Es decir, el kernel RBF es una combinación de todos los kernels polinomiales de grado $n\geq0$. Dado que n puede ser arbitrariamente grande, decimos que el kernel Gaussiano trabaja con vectores en infinitas dimensiones.}: $K(x_i,x_j)= exp (-\gamma\left\| x_i - x_j \right\|^2  ), \ \gamma>0.$
\end{itemize}

Donde $\gamma$ y $d$ son parámetros del kernel.

\subsubsection{Función de pérdida y regularización}
\label{regper}
El problema de optimización presentado en la sección anterior:

\begin{center}
$\begin{aligned}
\min\limits_{\beta, \beta_0}   \frac{1}{2} \| \beta \|^2 &+ C \sum\limits_{i=1}^N \xi_i \\
\textrm{sujeto a} \quad  y_{i}(\phi(x_i)^T \beta + \beta_0)
  &\geq 1 - \xi_i, i=1,\ldots,N    \\
  \xi_i &\geq 0 \ \forall i 
\end{aligned}
$
\end{center}

Puede reformularse como sigue \cite{statisticallearning} \cite{lopezmartinez2017regularization}:

\begin{center}
$
\min\limits_{\beta, \beta_0}  \sum_{i=0}^n [1-y_i(\beta_0 + x_i^T \beta)]_+ \frac{\lambda}{2} \| \beta \|^2
$
\end{center}

Donde el primer término de la suma es el término de pérdida (loss) y el segundo término es el término de regularización. $\lambda$ es un parámetro de regularización, relacionado a $\frac{1}{C}$ en la formulación inicial; y la función $(1-a)_+ = \max(0,1-a)$ es llamada función de pérdida de bisagra (del inglés, hinge loss function). \\

El término de perdida mide cuán bien el modelo aproximará las etiquetas del conjunto de entrenamiento. Es posible utilizar una función de pérdida distinta, por ejemplo el cuadrado de la función de pérdida de bisagra. Otras funciones de pérdida pueden apreciarse en la figura \ref{fig:loss_func}. En este trabajo se usará en todos los experimentos el cuadrado de la función de bisagra como penalización. \\


\begin{figure}[h!]
\begin{center}
  \includegraphics[width=0.7\textwidth]{Kap1/loss_func.png} 
  \end{center}
 \caption{ Gráfico de distintas funciones de pérdida. Créditos: Cagdas Ozgenc }
\label{fig:loss_func}
\end{figure}

Por otro lado, el término de regularización impone algún tipo de penalidad sobre la complejidad del modelo. Es posible utilizar distintos tipos de norma sobre los coeficientes $\beta$ en el término de regularización (e.g. $L_1$, $L_2$). Tanto $L_1$ como $L_2$ buscan mantener los coeficientes $\beta$ cercanos a cero, aunque presentan ciertas diferencias \cite{lopezmartinez2017regularization}:

\begin{itemize}
\item $L_1$ tiene la capacidad de llevar algunos de los coeficientes $\beta_i$ al valor 0 para $\lambda$ suficientemente grande, promoviendo  soluciones $\beta$ dispersas y realizando selección de variables (ver sección \ref{seleccion_v}) de forma implícita. Una desventaja es que $L_1$ tiende a descartar atributos correlacionados, incluso cuando todos son relevantes para el problema a tratar. En otras palabras, $L_1$ falla en identificar atributos que son relevantes de forma conjunta.
\item Contrariamente, $L_2$ no puede producir coeficientes $\beta$ dispersos, y por lo tanto no puede realizar selección de variables de forma automática. Esto implica que atributos correlacionados que no deberían ser ignorados por el modelo no serán ignorados.
\end{itemize}

En este trabajo se utilizará la penalidad $L2$ en todos los experimentos. \\

Finalmente, cabe mencionar que SVM es uno de los métodos de predicción con mayor sustento teórico, dado que se basa en aprendizaje estadístico o teoría VC (Vapnik-Chervonenkis). \cite{vapnik71uniform} \cite{vapnik74theory}.

\section{Antecedentes relevantes a esta tesina}

\par Como se adelantó anteriormente, en esta tesina se estudiará la aplicación de algoritmos de aprendizaje automatizado al problema de clasificar estrellas variables de tipo RRL en los datasets publicados por Carpyncho, correspondientes al relevamiento VVV. \\

\par Previamente, se ha explorado el desempeño de clasificadores automatizados de estrellas variables en varios estudios \cite{ej1}, \cite{ej2}, \cite{ej3}, \cite{ej4}.  Los dos antecedentes más relevantes de esta tesina, \cite{elorrieta} y \cite{jbc}, proponen procedimientos automatizados para clasificar RRL de subtipo ab en la VVV, basándose en sus curvas de luz. \\

En \cite{elorrieta} se concluye que AdaBoost\cite{adaboost}, un método basado en ensambles de árboles, obtiene consistentemente el mejor desempeño de entre una amplia selección de algoritmos de aprendizaje automatizado incluyendo SVM y redes neuronales profundas. El desempeño es estimado utilizando cross-validation, y a través de la comparación entre dos datasets que fueron clasificados por expertos humanos. Nótese que varias de las métricas utilizadas en este trabajo, como AUC o $F_1$, no son adecuadas para trabajar con datasets altamente desbalanceados. \\

Posteriormente, en \cite{jbc}, se refinaron las métricas de desempeño y se extiende el conjunto de atributos utilizado para describir estrellas variables, incorporando atributos de pseudocolor. En uno de los experimentos, se realizó una comparación entre el desempeño de distintos métodos de clasificación, incluyendo Random Forests y SVM. El mayor desempeño se obtuvo, nuevamente, utilizando ensambles de árboles.


\section{ Comparación entre Random Forest y Support Vector Machines}

Como ya se ha mencionado, Random Forest y SVM son dos potentes métodos de aprendizaje automatizado, que pueden ser aplicados tanto a problemas de regresión como de clasificación. En esta sección, se hará hincapié en ciertas características que distinguen ambos métodos, buscando comparar y contrastar la forma en que ambos operan. El objetivo es enumerar razones que puedan explicar por qué Random Forest parece funcionar mejor que SVM en estudios previos de clasificación de RRL.\\

En primer lugar, se debe notar que ambos métodos proceden de formas radicalmente distintas. En la fase de training, los árboles de decisión que conforman un random forest observan cada atributo uno a la vez, analizando si es beneficioso realizar divisiones para ciertos valores \cite{mitchell}. Por otro lado, las SVM consideran cada elemento del dataset como un punto en el espacio, utilizando los valores de todos los atributos en simultáneo para calcular un hiperplano separador \cite{svm2}. \\

Una primera consecuencia es que RF es inmune a \textbf{diferentes escalas} en los atributos \cite{statisticallearning}. Los datos no necesitan estar normalizados ni centrados para que RF funcione, mientras que la naturaleza geométrica de SVM implica que los distintos atributos necesariamente han de estar expresados en la misma escala \cite{svm_practical}. Más aún, las rutinas de optimización que usualmente implementan la fase de training en SVM pueden fallar en converger, o tardar significativamente más tiempo, si los datos no se encuentran escalados a [0,1] o [-1,1]
\cite{svm_practical}. Por lo tanto, resulta vital realizar un preprocesamiento adecuado a los datos a la hora de aplicar SVM. \\ 

Una segunda consecuencia es que RF puede \textbf{ignorar atributos que no son muy informativos} fácilmente, pues los árboles de decisión tienen un mecanismo simple para darse cuenta de que no sirven (ningún split será un buen candidato) \cite{statisticallearning}. De acuerdo a \cite{statisticallearning}, los árboles de decisión ``realizan una selección de variables internamente como una parte integral en su forma de proceder''. Ignorar atributos no informativos puede ser más complejo para SVM, pues la rutina de optimización tendría que asignar un valor nulo a los coeficientes correspondientes en $w$. La elección del tipo de penalidad (ver sección \ref{regper}) es importante en este sentido. Un cierto atributo puede ser poco informativo por distintos motivos: puede haber sido incluido en el dataset pero no contener información relevante para predecir la variable target, puede ser extremadamente ruidoso, etc.  Las técnicas de selección de variables  (Feature Selection) que se aplicarán en capítulos posteriores son una forma adecuada de deshacerse de atributos no informativos, y podrían reducir el impacto de este problema en SVM. \\

Resulta interesante explorar la potencial presencia de \textbf{atributos altamente correlacionados}. RF puede verse negativamente afectado por este fenómeno, pues la información contenida en dos atributos altamente correlacionados tendrá mayor probabilidad de ser utilizada para realizar una división en un nodo. Por otro lado, el impacto negativo puede verse disminuido por la forma en que los árboles de decisión son construidos. El algoritmo comprenderá que, si ya se realizó un split utilizando una cierta variable, realizar el mismo split utilizando una variable altamente correlacionada probablemente no ayudará a separar las clases objetivo. Resulta interesante explorar si las SVM se ven perjudicadas por la presencia de atributos correlacionados, y analizar el impacto de eliminar tales redundancias \cite{rf_collinearity}. La elección del tipo de penalidad (ver sección \ref{regper}) es un factor a considerar en este sentido\\

Otro punto a considerar es cómo manejar el \textbf{overfitting} (sobreajuste) durante la fase de training. RF requiere la estimación de \textbf{hiperparámetros}  para manejar apropiadamente el sobreajuste \cite{louppe2015understanding}, tal como el número máximo de atributos a considerar en cada nodo. Por otro lado, SVM requiere una cuidadosa estimación del hiperparámetro de regularización C, así como la elección de algún tipo de penalidad (\ref{regper}). Más aún, si se utiliza un kernel con parámetros adicionales como RBF, se requiere es
imar cuidadosamente otros hiperparámetros \cite{svm_practical}. Contrariamente, Random Forest es considerado un método off-the-shelf \cite{offshelf}, pues suele producir buenos resultados sin una optimización de hiperparámetros tan meticulosa. Por lo tanto, resulta de vital importancia una cuidadosa optimización de hiperparámetros de regularización y de kernel en SVM. \\

El marcado \textbf{imbalance de clases} presente en los datos, con aproximadamente 2000 elementos de clase negativa (no-RRL) por cada elemento de clase positiva (RRL), puede afectar negativamente el desempeño de RF y SVM. En \cite{jbc}, se determinó que corregir el imbalance de clases de estos datos mediante undersampling conduce a una pérdida de desempeño en Random Forest, siendo conveniente entrenar los modelos utilizando los datos sin balancear. Por otro lado, es posible que esto no sea cierto para SVM, dado que el imbalance de clases puede ocasionar pérdida de performance pues el hiperplano soporte elegido estará más alejado de la clase positiva, y habrá mayor cantidad de vectores soporte de la clase negativa \cite{imbalanced_svm}. Resulta por lo tanto interesante explorar diversas técnicas de undersampling y oversampling a la hora de aplicar SVM. \\

La existencia de \textbf{atributos ruidosos y outliers} en los datos es de esperarse en datasets astronómicos, que pueden incluir errores de medición y observación. RF no se ve afectado por outliers, pues los árboles de decisión funcionan creando cubetas (bins) que no se ven influenciadas por valores extremos \cite{statisticallearning}. Atributos que son altamente ruidosos no serán informativos a la hora de dividir la clase objetivo, y podrán ser ignorados por los árboles de decisión. Es interesante explorar distintos preprocesamientos tendientes a limpiar o suavizar los datos a la hora de aplicar SVM, pues puede ayudar a mitigar el efecto de outliers y ruido en los datos. Nótese que la función de pérdida utilizada por SVM (ver sección \ref{regper}) es menos sensible a outliers que otro tipo de funciones de pérdida, y la inclusión de regularización tratará de minimizar el valor de los coeficientes de SV, reduciendo el sobreajuste a outliers en los datos.\\

La siguiente tabla resume los puntos discutidos en esta sección. Durante el resto de este trabajo, se explorará cada uno de ellos. 

\begin{table}[h!]
\begin{tabular}{|l|l|}
\hline
\textbf{Aspecto}                                                                            & \textbf{Capítulo Relevante}                                  \\ \hline
\begin{tabular}[c]{@{}l@{}}Estimación de hiperparámetros óptimos\\ Overfitting\end{tabular} & Capítulos 2, 3.                                              \\ \hline
Diferentes escalas en los datos                                                             & Capítulo 4: Preprocesamientos                                \\ \hline
\begin{tabular}[c]{@{}l@{}}Atributos ruidosos\\ Existencia de outliers\end{tabular}          & Capítulo 4: Preprocesamientos                                \\ \hline
Atributos no informativas                                                                    & Capítulo 5: Feature selection y \\
 &  feature extraction \\ \hline
Atributos altamente correlacionados                                                          & Capitulo 6: Inspeccionando los datos                         \\ \hline
Imbalance de clases                                                                         & Capítulo 7: Imbalance de clases                              \\ \hline
\end{tabular}
\end{table}

Finalmente, en los capítulos 8 y 9 se ponderarán distintas teorías en base a los resultados obtenidos, y se extraerán conclusiones.






 