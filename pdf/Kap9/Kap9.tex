\chapter{Conclusión y trabajo futuro}

\section{Conclusión}
En esta tesina se abordó la problemática de clasificar estrellas variables de tipo RRL utilizando SVM, intentando igualar la performance obtenida por RF en trabajos previos, así como entender por qué los ensambles de árboles parecen funcionar mejor. \\

En primer lugar se exploró escalar y discretizar los datos de distintas formas, seleccionándose binning quantile junto con un escalado estándar como la elección óptima. Esto permitió mitigar el efecto de distintas escalas, outliers y ruido en los atributos. Posteriormente se hallaron hiperparámetros $C$ y $\gamma$ óptimos utilizando cross validation, de forma tal que no se sobreajusten los datos de entrenamiento. \\

En segundo lugar se evaluaron distintas técnicas de selección y extracción de variables, tendientes a reducir la cantidad de atributos usados para describir cada estrella. Se decidió eliminar 17 (14 en SVM-L) atributos utilizando filtros univariable, lo que permitió deshacerse de atributos no informativos y reducir la complejidad computacional y espacial significativamente. \\

Se procedió a inspeccionar los datos en detalle, buscando comprender qué atributos son los más informativos para detectar RRLs. También se identificó la presencia de bloques de atributos altamente correlacionados en nuestros tiles, pero se descartó que esto tuviese un impacto negativo en la performance de los clasificadores SVM. \\

Se experimentó con distintas técnicas para corregir el marcado desbalance de clases presente en los datos. Se concluyó que el uso de oversampling aleatorio conduce a una leve mejoría en SVM Lineal, en tanto que SVM-RBF no mejora su performance al corregir el desbalance. \\

Como resultado final, la performance de SVM logró igualar a la de RF en varios de los tiles estudiados, aunque RF continúa siendo superior en otros (ver figura \ref{fig:poder_predictivo_curvas}). En este punto, ya se han abordado todas las razones obvias por las cuales SVM podría funcionar peor que RF: sobreajuste, escalado de los datos, ruido y outliers, atributos no informativos o altamente correlacionados y desbalance de clases. \\

Finalmente, se profundiza sobre el hecho de que el problema de clasificación estudiado en esta tesina incumple una asunción básica en aprendizaje automatizado clásico: los datasets de entrenamiento y de testeo no están regidos por la misma distribución de probabilidad. Este fenómeno, llamado dataset drift, tiene poca visibilidad en el campo de aprendizaje automatizado a pesar de ser muy común en la práctica. \\

Se propuso que la marcada diferencia entre las distribuciones de probabilidad subyacentes a cada tile es la causa por la cual la performance en test varía tanto entre distintos tiles. Basándose en resultados de trabajos previos, se conjetura que RF se ve menos afectado que SVM por la presencia de dataset shift, lo cuál explicaría por qué SVM es incapaz de superar a RF en pares de tiles espacialmente distantes. \\


Como experimento final se intentó corregir, sin éxito, la divergencia entre las distribuciones; eliminando atributos que contribuyen marcadamente a distinguir tiles. Considerando que prácticamente todos los atributos contribuyen a la divergencia, parece ser necesario recurrir a métodos más sofisticados para mitigar los efectos del dataset shift presente. \\

\section{Trabajo futuro}

Con el objeto de mantener la longitud de este trabajo acotada, se optó por no realizar ciertos experimentos: 

\begin{itemize}
\item Resultaría interesante evaluar si varias de las técnicas aplicadas en este trabajo, tales como corrección del imbalance de clases, logran mejorar la performance de RF. En esta tesina los esfuerzos se concentraron únicamente en mejorar SVM.
\item Puede ser beneficioso utilizar otros algoritmos de aprendizaje automatizado para abordar este problema. En particular, Gradient Boosting \cite{friedman2000greedy} \cite{friedman2} es una opción muy interesante teniendo en cuenta el alto desempeño obtenido por Adaboost a la hora de clasificar RRLs \cite{elorrieta}.
\item La mayoría de los experimentos de este trabajo se concentraron en agregar preprocesamientos y modificaciones a SVM. Sin embargo, para comprender por qué RF funciona mejor que SVM, puede ser interesante diseñar otro conjunto de experimentos enfocados en RF, intentando entender qué es lo que ocasiona que funcione tan bien.
\item Sería interesante realizar un análisis de aquellas estrellas que están siendo clasificadas incorrectamente por SVM, intentando determinar si hay algún patrón en ellas que SVM no es capaz de aprender. También sería de interés evaluar si las estrellas incorrectamente clasificadas por RF son un subconjunto de aquellas incorrectamente clasificadas por SVM.
\end{itemize}

Respecto a la presencia de dataset shift en nuestros datos, se propone como trabajo futuro:

\begin{itemize}
\item Uilizar importance reweighting (\cite{kouw2019introduction}, \cite{non-stationary} , \cite{GeetaDharani2019CovariateSA}) para mitigar el efecto de covariate shift. Esto tiene el potencial de mejorar la performance de los clasificadores. Debido a la alta dimensionalidad de los datos, se deberá buscar métodos aproximados para hallar los coeficientes asociados a cada instancia de entrenamiento.
\item Explorar las múltiples técnicas para abordar la presencia de covariate shift que han sido propuestas en trabajos recientes \cite{GeetaDharani2019CovariateSA}, incluyendo mapeo de subespacios \cite{kouw2019introduction} y reducción de dimensionalidad extrema \cite{wang2018extreme}.
\item Realizar experimentos para verificar si, efectivamente, RF es más robusto que SVM ante datos que presentan covariate shift.
\item Una alternativa es combinar datos de distintos tiles a la hora de entrenar, en vez de utilizar datos de un único tile. Esto permitirá que los clasificadores no estén tan sesgados hacia un área particular de la vía láctea. 
\item Finalmente, se sugiere modificar el conjunto de atributos utilizado para describir cada estrella, tratando de codificar la misma información de alguna forma que sirva para caracterizar estrellas independientemente del tile al que pertenece.
\end{itemize}

Otras avenidas de trabajo futuro incluyen:

\begin{itemize}
\item Extender los datos recolectados en Carpyncho, agregando más tiles de la VVV y etiquetando RRLs identificadas en otros trabajos.
\item Realizar experimentos similares para tratar de clasificar otro tipo de estrellas variables en la VVV.
\end{itemize}



